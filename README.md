# üìä An√°lise de sentimento de reviews de e-commerce

 A partir de um dataset p√∫blico do Kaggle, foi constru√≠do um pipeline completo de Machine Learning, desde o pr√©-processamento dos dados at√© a an√°lise comparativa de m√∫ltiplos modelos de classifica√ß√£o para determinar se uma review de produto √© **positiva** ou **negativa**.

## üõ†Ô∏è Pipeline do Projeto

#### An√°lise Explorat√≥ria de Dados (EDA)
O primeiro passo foi explorar o conjunto de dados. A partir da abordagem top-down, foi observado o conte√∫do dos arquivos .csv e o que seria significativo para o projeto. <br> <br>
Ao ser determinada como base principal, `olist_order_reviews_dataset.csv` foi utilizada para entender a distribui√ß√£o das notas de avalia√ß√£o (`review_score`). A partir dessa an√°lise, foi criada a vari√°vel alvo `sentimento`:
- **Reviews Positivas:** reviews com notas 4 e 5.
- **Reviews Negativas:** reviews com notas 1 e 2.

> As reviews com nota 3 foram consideradas neutras e removidas do dataset de treino para criar um sinal de classifica√ß√£o mais claro e diminuir a ambiguidade para o modelo;
> No entanto, **implementa√ß√µes posteriores** podem considerar especificamente reviews de nota 3 e avaliar os coment√°rios em neutros positivos e neutros negativos.

#### Pr√©-processamento de Texto
Para que o texto pudesse ser compreendido pelos algoritmos, foi aplicada uma s√©rie de t√©cnicas de limpeza e normaliza√ß√£o nos coment√°rios das reviews:

Convers√£o para min√∫sculas; <br>
Remo√ß√£o de n√∫meros e sinais de pontua√ß√£o; <br>
Remo√ß√£o de acentos; <br>
Remo√ß√£o de *stopwords* (palavras comuns como "o", "de", "que") utilizando a biblioteca NLTK (_Natural Language Tool Kit_) para o portugu√™s. <br>

#### Vetoriza√ß√£o com TF-IDF
Os textos limpos foram transformados em vetores num√©ricos utilizando a t√©cnica **TF-IDF (Term Frequency-Inverse Document Frequency)**. <br> <br>
Esse m√©todo calcula a import√¢ncia de cada palavra para uma review espec√≠fica em rela√ß√£o a todas as outras reviews, permitindo que o modelo identifique as palavras que s√£o os sinais mais fortes de sentimento positivo ou negativo. <br>
Como funciona? <br> <br>
A pontua√ß√£o final de cada palavra em uma review √© feita por TF * IDF <br>
Score TF-IDF = (Frequ√™ncia da palavra na review) x (Raridade da palavra em todo o dataset) <br>

Exemplo: <br>
Total de reviews no dataset = 10.000 <br>
Review A: "Recebi o produto, achei **√≥timo**, **√≥timo** mesmo. Recomendo a todos." <br>
Review B: "A entrega do **produto** atrasou. O **produto** veio com defeito." <br>

| M√©trica | C√°lculo para "√≥timo" (Review A) | C√°lculo para "produto" (Review B) |
| :--- | :--- | :--- |
| **Frequ√™ncia (TF)** | A palavra aparece **2 vezes** na review.<br>`2 / 10 = 0.2` | A palavra aparece **2 vezes** na review.<br>`2 / 10 = 0.2` |
| **Raridade (IDF)** | A palavra est√° em **300** de 10.000 reviews.<br>`log(10.000 / 300) ‚âà 1.52` | A palavra est√° em **8.500** de 10.000 reviews.<br>`log(10.000 / 8.500) ‚âà 0.07` |
| **Score Final (TF-IDF)** | `0.2 * 1.52 = 0.304` | `0.2 * 0.07 = 0.014` |
| **Conclus√£o** | **Score ALTO**<br>O modelo identifica "√≥timo" como uma palavra-chave fort√≠ssima para o sentimento. | **Score BAIXO**<br>O modelo aprende a ignorar "produto" como um indicador de sentimento. |

#### Modelagem e Otimiza√ß√£o
Inicialmente, um modelo de **Regress√£o Log√≠stica** foi treinado. A an√°lise de seus resultados mostrou um baixo **recall** para a classe negativa, indicando que o modelo n√£o estava conseguindo identificar uma grande parte dos clientes insatisfeitos.
> E n√£o se preocupar com o recall negativo de uma an√°lise de _review de clientes_ significa ignorar os pontos de melhoria que os clientes est√£o ilustrando.

Para resolver isso, foi aplicada a t√©cnica de **pondera√ß√£o de classes** (`class_weight='balanced'`), que instrui o modelo a dar mais import√¢ncia √† classe minorit√°ria (negativa) durante o treinamento. Isso resultou em uma melhora significativa no recall.
> Diminui√ß√£o de **falsos positivos**, ou seja, reviews realmente negativas consideradas pelo modelo como positivas (canto superior direito) <br>
> Aumento de **falsos negativos**, ou seja, reviews positivas consideradas como negativas (canto inferior esquerdo)
>> Nota: melhor priorizar o acerto em reviews que s√£o realmente negativas e "perder tempo" analisando reviews positivas consideradas negativas, do que nem sequer analisar algumas reviews negativas.

![Gr√°fico de compara√ß√£o de matrizes de confus√£o para o modelo de regress√£o log√≠stica balanceado e n√£o balanceado](./img/comparacao_logisticRegression.png)


#### Compara√ß√£o de M√∫ltiplos Modelos
Para garantir a melhor solu√ß√£o, quatro modelos de classifica√ß√£o diferentes foram comparados:
##### Regress√£o Log√≠stica
> R√°pido e direto, por√©m √© baseado em apenas uma equa√ß√£o linear. Atribui um peso a todas as palavras da review (positivo ou negativo, 0 ou 1) e depois calcula a probabilidade da review ser positiva ou negativa no geral.
##### Naive Bayes
> R√°pido, por√©m "ing√™nuo" (do ingl√™s, _naive_). Considera a presen√ßa de uma palavra em todas as reviews (indicadas positivas ou negativas) e faz uma "aposta" para responder se a review √© positiva ou negativa com base nas palavras.
##### Random Forest
> Mais robusto, decis√£o baseada em consenso (dificil de acontecerem erros absurdos - resiste a _overfitting_), por√©m mais demorado.
> _Overfitting_ ocorre quando um modelo fornece previs√µes precisas para dados de treinamento, mas n√£o para novos dados.
##### Support Vector Machine (SVM)
> √ìtimo para encontrar rela√ß√µes complexas e n√£o-lineares, por√©m muito lento.

<br>

Todos os modelos foram avaliados com foco nas m√©tricas de performance para a classe negativa (Precis√£o, Recall e F1-Score).

---

## üìà Resultados e An√°lise

### Performance do Modelo Vencedor
A an√°lise comparativa mostrou que, embora o SVM tenha o melhor F1-Score geral, o modelo de **Regress√£o Log√≠stica com `class_weight='balanced'`** apresentou o **maior Recall (0.71)** entre os modelos de alta performance. Dado que o objetivo de identificar o m√°ximo poss√≠vel de clientes insatisfeitos, este foi escolhido como o modelo final recomendado.

![Gr√°fico de compara√ß√£o entre os resultados dos modelos](./img/comparacao_modelos.png)

### Entendendo a defini√ß√£o de sentimento positivo e negativo
Analisando os coeficientes do modelo de Regress√£o Log√≠stica, foi poss√≠vel extrair as palavras que mais influenciam a previs√£o:

**Principais palavras indicando uma review POSITIVA:**
```
antes, rapida, perfeito, excelente, lindo, amei, parabens, rapido, otimo, otima
```
* **Ideia:** A **velocidade da entrega** √© o fator mais crucial para a satisfa√ß√£o do cliente.

**Principais palavras indicando uma review NEGATIVA:**
```
pessima, pessimo, recebi, comprei, nao, passou, baixa, aguardando, veio, ruim
```
* **Ideia:** Os problemas est√£o centrados na **qualidade do produto** (`pessimo`, `ruim`, `baixa`) e em **falhas na entrega ou no pedido** (`nao recebi`, `veio errado`, `faltando`).

---

## üöÄ Como Executar o Projeto

## üìÑ Data Source
Os dados utilizados neste projeto s√£o p√∫blicos e foram disponibilizados pela Olist na plataforma Kaggle. O conjunto de dados original cont√©m informa√ß√µes sobre pedidos, produtos, pagamentos e, mais importante, as avalia√ß√µes dos clientes, que foram a base para esta an√°lise. <br> <br>
**Dataset:** [Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)

### Pr√©-requisitos
- Python 3.8+

### Instala√ß√£o
1. Clone este reposit√≥rio:
   ```bash
   git clone https://github.com/jampani1/from-data-to-feelings.git
   ```

2. Baixe os recursos necess√°rios da NLTK (execute uma vez em um terminal Python):
   ```python
   import nltk
   nltk.download('stopwords')
   ```
### Execu√ß√£o
Execute todos os scripts para visualiza√ß√£o de todo o pipeline, mas para a compara√ß√£o, o principal √©:
```bash
python comparison.py
```
Os gr√°ficos de compara√ß√£o ser√£o salvos como arquivos `.png` na pasta `img/`.

---

## üîÆ Melhorias Futuras
- **Refinamento do Pr√©-processamento:** <br>
Testar t√©cnicas como _Lematiza√ß√£o_ ou _Stemming_. Al√©m de considerar que as reviews consideram compra e pedido (palavras que aparecem mas n√£o possuem significado para considera√ß√£o de positivo/negativo).

>_Stemming_ √© a retirada do sufixo das palavras para chegar ao stem (tronco); <br>
Exemplo: correndo; correu se tornam corr.

>_Lematiza√ß√£o_ usa um dicion√°rio para transformar o stem das palavras em uma palavra com valor gramatical; <br>
Exemplo: verbos v√£o para o infinitivo e subjetivos v√£o para o singular.


---
Este projeto foi desenvolvido por mim, Maur√≠cio J Souza, como uma demonstra√ß√£o de habilidades em ci√™ncia de dados e machine learning.

Para considera√ß√µes, perguntas ou oportunidades, sinta-se √† vontade para me encontrar em:

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/mauriciojampani/) [![Gmail](https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:mmjampani13@gmail.com)  [![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/jampani1)
